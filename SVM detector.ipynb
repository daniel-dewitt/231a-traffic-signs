{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This SVM detector was adapted from my submission from problem set 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "RUN_DETECTOR Given an image, runs the SVM detector and outputs bounding\n",
    "boxes and scores\n",
    "\n",
    "Arguments:\n",
    "    im - the image matrix\n",
    "\n",
    "    clf - the sklearn SVM object. You will probably use the \n",
    "        decision_function() method to determine whether the object is \n",
    "        a face or not.\n",
    "        http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "    window_size - an array which contains the height and width of the sliding\n",
    "    \twindow\n",
    "\n",
    "    cell_size - each cell will be of size (cell_size, cell_size) pixels\n",
    "\n",
    "    block_size - each block will be of size (block_size, block_size) cells\n",
    "\n",
    "    nbins - number of histogram bins\n",
    "\n",
    "Returns:\n",
    "    bboxes - D x 4 bounding boxes that tell [xmin ymin width height] per bounding\n",
    "    \tboxQD\n",
    "\n",
    "    scores - the SVM scores associated with each bounding box in bboxes\n",
    "\n",
    "You can compute the HoG features using the compute_hog_features() method\n",
    "that you implemented in PS3. We have provided an implementation in utils.py,\n",
    "but feel free to use your own implementation. You will use the HoG features\n",
    "in a sliding window based detection approach.\n",
    "\n",
    "Recall that using a sliding window is to take a certain section (called the \n",
    "window) of the image and compute a score for it. This window then \"slides\"\n",
    "across the image, shifting by either n pixels up or down (where n is called \n",
    "the window's stride). \n",
    "\n",
    "Using a sliding window approach (with stride of block_size * cell_size / 2),\n",
    "compute the SVM score for that window. If it's greater than 1 (the SVM decision\n",
    "boundary), add it to the bounding box list. At the very end, after implementing \n",
    "nonmaximal suppression, you will filter the nonmaximal bounding boxes out.\n",
    "'''\n",
    "def run_detector(im, clf, window_size, cell_size, block_size, nbins, thresh=1):\n",
    "    W = window_size[0]\n",
    "    H = window_size[1]\n",
    "    stride = int(block_size * cell_size / 2)\n",
    "    \n",
    "    bboxes = []\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(0,im.shape[0] - H,stride):\n",
    "        for j in range(0,im.shape[0] - W,stride):\n",
    "            features = compute_hog_features( im[i:i+H, j:j+W], cell_size, block_size, nbins)\n",
    "            score = clf.decision_function(features.reshape(1,-1))\n",
    "            if(score > -1.0):\n",
    "                bboxes.append([j,i,W,H])\n",
    "                scores.append(score)\n",
    "    \n",
    "    \n",
    "    bboxes = np.array(bboxes)\n",
    "    bboxes = np.reshape(bboxes,(bboxes.size/4,4))\n",
    "    scores = np.array(scores)\n",
    "    return bboxes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NON_MAX_SUPPRESSION Given a list of bounding boxes, returns a subset that\n",
    "uses high confidence detections to suppresses other overlapping\n",
    "detections. Detections can partially overlap, but the\n",
    "center of one detection can not be within another detection.\n",
    "\n",
    "Arguments:\n",
    "    bboxes - ndarray of size (N,4) where N is the number of detections,\n",
    "        and each row is [x_min, y_min, width, height]\n",
    "    \n",
    "    confidences - ndarray of size (N, 1) of the SVM confidence of each bounding\n",
    "    \tbox.\n",
    "\n",
    "    img_size - [height,width] dimensions of the image.\n",
    "\n",
    "Returns:\n",
    "    nms_bboxes -  ndarray of size (N, 4) where N is the number of non-overlapping\n",
    "        detections, and each row is [x_min, y_min, width, height]. Each bounding box\n",
    "        should not be overlapping significantly with any other bounding box.\n",
    "\n",
    "In order to get the list of maximal bounding boxes, first sort bboxes by \n",
    "confidences. Then go through each of the bboxes in order, adding them to\n",
    "the list if they do not significantly overlap with any already in the list. \n",
    "A significant overlap is if the center of one bbox is in the other bbox.\n",
    "'''\n",
    "def non_max_suppression(bboxes, confidences):\n",
    "    indices = np.argsort(confidences,axis=0)[::-1] #indices that sort confidences in reverse order\n",
    "    confidences = confidences[indices]\n",
    "    bboxes = bboxes[indices].reshape((bboxes.shape[0],4))\n",
    "    nms_bboxes = bboxes[0,:].reshape((1,4))\n",
    "    \n",
    "    for i in range(1,confidences.size):\n",
    "        center = [bboxes[i,0]+bboxes[i,2]/2 , bboxes[i,1]+bboxes[i,3]/2]\n",
    "        for j in range(0,nms_bboxes.shape[0]):\n",
    "            #if not within width or height of bounding box, add to array of bounding boxes\n",
    "            if not ((center[0] > nms_bboxes[j,0] and center[0] < nms_bboxes[j,0] + nms_bboxes[j,2]) and\n",
    "                (center[1] > nms_bboxes[j,1] and center[1] < nms_bboxes[j,1] + nms_bboxes[j,3])):\n",
    "                nms_bboxes = np.append(nms_bboxes,bboxes[j,:].reshape(1,4),axis=1)\n",
    "            \n",
    "    return nms_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LISA/negatives/negativePics\\nosign00000.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('<U43') and format specifier ('%.5f')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                     \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a float is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8b37ab7227c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeatures_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_positive_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cropped_signs/stop_signs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnum_negative_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfeatures_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_random_negative_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LISA/negatives/negativePics'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_negative_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'features_pos.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'features_neg.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_neg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Daniel\\Documents\\Stanford\\2016-2017 - Q3 - Spring\\Computer Vision\\Python\\Project\\utils.py\u001b[0m in \u001b[0;36mget_random_negative_features\u001b[0;34m(non_face_scn_path, cell_size, window_size, block_size, nbins, num_samples)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mimage_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_face_scn_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_face_scn_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mnum_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mnum_sample_per_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtotal_block_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcell_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[1;32m   1161\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[1;32m   1163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mfooter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfooter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Mismatch between array dtype ('<U43') and format specifier ('%.5f')"
     ]
    }
   ],
   "source": [
    "block_size = 6\n",
    "cell_size = 3\n",
    "nbins = 9\n",
    "window_size = np.array([32, 32])\n",
    "\n",
    "# compute or load features for training\n",
    "if not (os.path.exists('features_pos.npy') and os.path.exists('features_neg.npy')):\n",
    "    features_pos = get_positive_features('cropped_signs/stop_signs', cell_size, window_size, block_size, nbins)\n",
    "    num_negative_examples = 10000\n",
    "    features_neg = get_random_negative_features('LISA/negatives/negativePics', cell_size, window_size, block_size, nbins, num_negative_examples)\n",
    "    np.save('features_pos.npy', features_pos)\n",
    "    np.save('features_neg.npy', features_neg)\n",
    "else:\n",
    "    features_pos = np.load('features_pos.npy')\n",
    "    features_neg = np.load('features_neg.npy')\n",
    "\n",
    "X = np.vstack((features_pos, features_neg))\n",
    "Y = np.hstack((np.ones(len(features_pos)), np.zeros(len(features_neg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the SVM\n",
    "clf = LinearSVC(C=1, tol=1e-6, max_iter=10000, fit_intercept=True, loss='squared_hinge')\n",
    "clf.fit(X, Y)\n",
    "score = clf.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part A: Sliding window detector\n",
    "im = cv2.imread(r'LISA\\vid1\\frameAnnotations-vid_cmp1.avi_annotations\\stop_1323812801.avi_image4.png')\n",
    "im_yuv = cv2.cvtColor(im, cv2.COLOR_BGR2YUV) #converting to YUV\n",
    "im_yuv[:,:,0] = cv2.equalizeHist(im_yuv[:,:,0]) #equalize the histogram of the Y channel\n",
    "im = cv2.cvtColor(im_yuv, cv2.COLOR_YUV2BGR) #converting back to BGR\n",
    "im = cv2.cvtColor(im_yuv, cv2.COLOR_BGR2GRAY) #flattening\n",
    "bboxes, scores = run_detector(im, clf, window_size, cell_size, block_size, nbins)\n",
    "plot_img_with_bbox(im, bboxes, 'Without nonmaximal suppresion')\n",
    "plt.show()\n",
    "\n",
    "# Part B: Nonmaximal suppression\n",
    "bboxes = non_max_suppression(bboxes, scores)\n",
    "plot_img_with_bbox(im, bboxes, 'With nonmaximal suppresion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bboxes, scores = run_detector(im, clf, window_size, cell_size, block_size, nbins)\n",
    "plot_img_with_bbox(im, bboxes, 'Detected Signs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
